{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9d7425-61a1-4b42-8af5-ded59b078d4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training with Intel-extension for PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e3f8c9-a1ea-4b70-8eb7-2ea009bca2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 7.5\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(*torch.__config__.show().split(\"\\n\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from statistics import mean\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c4e91e-c8d2-4553-99c9-e547e5fe955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "use_ipex=True\n",
    "\n",
    "if use_ipex: \n",
    "    import intel_pytorch_extension as ipex\n",
    "    device = torch.device(\"xpu\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97a10f-5215-42a4-ab6c-f9dfee226fe1",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b256fc1b-0057-4b8a-81f7-c870a62ccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist.models import ResNet18\n",
    "from medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal\n",
    "from medmnist.evaluator import getAUC, getACC\n",
    "from medmnist.info import INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccdb44-6515-4ea1-9a41-1732c9dd3a74",
   "metadata": {},
   "source": [
    "#### Define learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d667bd-07c1-476b-b867-86e0b4699442",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "batch_size = 1024\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8d983-bddb-451f-89e3-1c30415f2c87",
   "metadata": {},
   "source": [
    "#### Load and preprocess dataset into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a61d85-c8fc-42f3-8d72-eabcc0082e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = True\n",
    "input_root = 'tmp_data/'\n",
    "data_flag = 'breastmnist'\n",
    "\n",
    "flag_to_class = {\n",
    "    \"pathmnist\": PathMNIST,\n",
    "    \"chestmnist\": ChestMNIST,\n",
    "    \"dermamnist\": DermaMNIST,\n",
    "    \"octmnist\": OCTMNIST,\n",
    "    \"pneumoniamnist\": PneumoniaMNIST,\n",
    "    \"retinamnist\": RetinaMNIST,\n",
    "    \"breastmnist\": BreastMNIST,\n",
    "    \"organmnist_axial\": OrganMNISTAxial,\n",
    "    \"organmnist_coronal\": OrganMNISTCoronal,\n",
    "    \"organmnist_sagittal\": OrganMNISTSagittal,\n",
    "}\n",
    "\n",
    "DataClass = flag_to_class[data_flag]\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ae4aec4-5fdf-4150-a2d6-a770c8e1be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: tmp_data/breastmnist.npz\n",
      "Using downloaded and verified file: tmp_data/breastmnist.npz\n",
      "Using downloaded and verified file: tmp_data/breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(root=input_root, split='train', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(root=input_root, split='test', transform=data_transform, download=download)\n",
    "val_dataset = DataClass(root=input_root,split='val',transform=data_transform, download=download)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(dataset=val_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2ec2d-6327-42d6-8cc2-b472eaff0d71",
   "metadata": {},
   "source": [
    "#### Define models and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46f4ea55-9435-4eb3-9034-1ee5d76f2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(in_channels=n_channels, num_classes=n_classes).to(device)\n",
    "\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b769d-cfa1-4e91-be87-8b4ea4cb8fec",
   "metadata": {},
   "source": [
    "#### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2799c88e-9e79-417d-8585-86d73ec2aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, device, task):\n",
    "    ''' training function\n",
    "    :param model: the model to train\n",
    "    :param optimizer: optimizer used in training\n",
    "    :param criterion: loss function\n",
    "    :param train_loader: DataLoader of training set\n",
    "    :param device: cpu, xpu\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ce37f-b1bd-4865-bd9b-c07daa2f7b85",
   "metadata": {},
   "source": [
    "#### Define validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bb5b49a-1129-496c-a673-2bd03ea1f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_loader, device, val_auc_list, task, dir_path, epoch):\n",
    "    ''' validation function\n",
    "    :param model: the model to validate\n",
    "    :param val_loader: DataLoader of validation set\n",
    "    :param device: cpu or xpu\n",
    "    :param val_auc_list: the list to save AUC score of each epoch\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "    :param dir_path: where to save model\n",
    "    :param epoch: current epoch\n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            \n",
    "            outputs = model(inputs.to(device))\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).to(device)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs = m(outputs).to(device)\n",
    "            else:\n",
    "                targets = targets.squeeze().long().to(device)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(outputs).to(device)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "                \n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc = getAUC(y_true, y_score, task)\n",
    "        val_auc_list.append(auc)\n",
    "\n",
    "    state = {\n",
    "        'net': model.state_dict(),\n",
    "        'auc': auc,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "\n",
    "    path = os.path.join(dir_path, 'ckpt_%d_auc_%.5f.pth' % (epoch, auc))\n",
    "    torch.save(state, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb5180-9135-471a-a7ea-3b8c6ef88848",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b2f0fe-729b-40ea-93ce-0140e9fa2c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.4526829719543457sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.412468671798706sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.2222394943237305sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:13,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.1777422428131104sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:07<00:10,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.3112516403198242sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:09<00:09,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.22499418258667sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:11<00:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.1669392585754395sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:12<00:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.43815279006958sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:14<00:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.5158050060272217sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:17<00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1.3670127391815186sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training per epoch took 1.3289288997650146s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## save the checkpoints of all epochs\n",
    "val_auc_list = []\n",
    "dir_path = os.path.join(\"./output\", '%s_checkpoints' % (data_flag))\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    \n",
    "time_training=[]\n",
    "\n",
    "## finally training \n",
    "for epoch in trange(0,nb_epochs):\n",
    "        time1 = time.time()\n",
    "        train(model, optimizer, criterion, train_loader, device, task)\n",
    "        time_epoch = time.time()-time1 \n",
    "        print(\"training \"+str(time_epoch)+ \"sec\")\n",
    "        \n",
    "        if nb_epochs>0: # avoid any warm-up effect \n",
    "            time_training.append(time_epoch)\n",
    "            \n",
    "        val(model, val_loader, device, val_auc_list, task, dir_path, epoch)\n",
    "\n",
    "average_training_time_per_epoch=mean(time_training)\n",
    "print(\"Training per epoch took \"+str(average_training_time_per_epoch) + \"s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59077e-6a43-443c-a46c-9e8e8e542e07",
   "metadata": {},
   "source": [
    "#### Define test function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dbaeea0-f31f-4f90-acca-34bf0ddb1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, split, data_loader, device, flag, task):\n",
    "    ''' testing function\n",
    "    :param model: the model to test\n",
    "    :param split: the data to test, 'train/val/test'\n",
    "    :param data_loader: DataLoader of data\n",
    "    :param device: cpu or xpu\n",
    "    :param flag: subset name\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            \n",
    "            outputs = model(inputs.to(device))\n",
    "            \n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).to(device)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs = m(outputs).to(device)\n",
    "            else:\n",
    "                targets = targets.squeeze().long().to(device)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(outputs).to(device)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc = getAUC(y_true, y_score, task)\n",
    "        acc = getACC(y_true, y_score, task)\n",
    "        print('%s AUC: %.5f ACC: %.5f' % (split, auc, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90334072-c266-46d6-818a-a040b6410dcf",
   "metadata": {},
   "source": [
    "#### Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e934524-e9fb-425c-b5e7-480f8cf4d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 is the best model\n",
      "==> Testing model...\n",
      "==> Evaluating ...\n",
      "train AUC: 0.67334 ACC: 0.45093\n",
      "val AUC: 0.72270 ACC: 0.45000\n",
      "test AUC: 0.66801 ACC: 0.43500\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "auc_list = np.array(val_auc_list)\n",
    "index = auc_list.argmax()\n",
    "print('epoch %s is the best model' % (index))\n",
    "\n",
    "print('==> Testing model...')\n",
    "restore_model_path = os.path.join(dir_path, 'ckpt_%d_auc_%.5f.pth' % (index, auc_list[index]))\n",
    "#restore_model_path = './output/pathmnist_checkpoints/ckpt_22_auc_0.99737.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(restore_model_path)['net'])\n",
    "        \n",
    "print('==> Evaluating ...')\n",
    "test(model,'train',train_loader, device, data_flag, task)\n",
    "test(model,'val', val_loader, device, data_flag, task)\n",
    "test(model, 'test', test_loader,device, data_flag, task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ef2b2-50fc-405d-bb04-a7d6b30aaada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
